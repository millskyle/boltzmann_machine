{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import numpy as np\n",
    "import h5py\n",
    "import progressbar\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_batch(N):\n",
    "    batch = np.zeros((N,16))\n",
    "    for n in range(N):\n",
    "        batch[n,np.random.randint(0,16)] = 1\n",
    "    return batch\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py:1662: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n",
      "\r",
      "                                                                               \r",
      "\r",
      "N/A% (0 of 10000) |                      | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10000 of 10000) |##################| Elapsed Time: 0:00:28 Time:  0:00:28\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from rbm import RBM\n",
    "rbm = RBM(visible_size=16, hidden_size=1024)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "rbm.attach_session(sess)\n",
    "\n",
    "bar = progressbar.ProgressBar()\n",
    "for i in bar(range(10000)):\n",
    "    rbm.train(v_init=training_batch(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rbm.inference(v_init=np.random.rand(32,16))\n",
    "X = training_batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8.,  0.,  0., 13.,  0.,  0.,  8.,  0.,  0.,  3.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(X.sum(axis=1), alpha=0.7)\n",
    "ax.hist(x.sum(axis=1), alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_batch(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import BernoulliRBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -3.88, time = 0.83s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -3.96, time = 1.60s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -3.93, time = 1.45s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -3.87, time = 1.46s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -3.92, time = 1.47s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -3.99, time = 1.46s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -3.90, time = 1.45s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -3.90, time = 1.48s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.94, time = 1.50s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.06, time = 1.53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BernoulliRBM(batch_size=10, learning_rate=0.01, n_components=1024, n_iter=10,\n",
       "       random_state=0, verbose=True)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm = BernoulliRBM(n_components=1024, learning_rate=0.01, random_state=0, verbose=True)\n",
    "rbm.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "t = X_train[0].copy()\n",
    "for i in range(40):\n",
    "    t = rbm.gibbs(t)*1.0\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
